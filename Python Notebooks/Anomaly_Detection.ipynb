{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f0b8cb",
   "metadata": {},
   "source": [
    "# Anomaly Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10232150",
   "metadata": {},
   "source": [
    "* Finding unusual clients who don’t behave like anyone else:\n",
    "    * Very low arrears but very bad score\n",
    "    * Very high arrears but perfect score\n",
    "\n",
    "* These are either golden opportunities or data quality errors.\n",
    " Isolation Forest or simple Deep Autoencoders can catch anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590f2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba581dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anomaly detection completed. Output saved as 'clients_with_anomalies.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Unique_Scores_for_Client/clients_with_individual_segment_score_with_tiers.csv\")\n",
    "\n",
    "# Select relevant numerical features for anomaly detection\n",
    "features = ['Arrears Balance', 'dp1 Score', 'dp3 Score', 'Segment_Risk_Score']\n",
    "X = df[features].copy()\n",
    "\n",
    "# missing values \n",
    "X = X.dropna()\n",
    "\n",
    "# index mapping \n",
    "original_index = X.index\n",
    "\n",
    "# Normalising data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# fitting Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(X_scaled)\n",
    "\n",
    "# Maping labels to readable format: -1 = anomaly, 1 = normal\n",
    "anomaly_labels = pd.Series(anomaly_labels, index=original_index)\n",
    "anomaly_labels = anomaly_labels.map({1: \"Normal\", -1: \"Anomaly\"})\n",
    "\n",
    "# Original dataset\n",
    "df['Anomaly Label'] = \"Normal\"\n",
    "df.loc[anomaly_labels.index, 'Anomaly Label'] = anomaly_labels\n",
    "\n",
    "# REsult\n",
    "df.to_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Anomaly_Detection/clients_with_anomalies.csv\", index=False)\n",
    "\n",
    "print(\" Anomaly detection completed. Output saved as 'clients_with_anomalies.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f1192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Anomaly detection completed. Output saved as 'x.csv'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Unique_Scores_for_Client/clients_sorted_by_risk.csv\")\n",
    "\n",
    "#  relevant numerical features for anomaly detection\n",
    "features = ['Arrears Balance', 'dp1 Score', 'dp3 Score', 'Segment_Risk_Score']\n",
    "X = df[features].copy()\n",
    "\n",
    "#  missing values \n",
    "X = X.dropna()\n",
    "\n",
    "# Keep index mapping to rejoin later\n",
    "original_index = X.index\n",
    "\n",
    "# Normalize (scale) the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize and fit Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(X_scaled)\n",
    "\n",
    "# Map labels to readable format: -1 = anomaly, 1 = normal\n",
    "anomaly_labels = pd.Series(anomaly_labels, index=original_index)\n",
    "anomaly_labels = anomaly_labels.map({1: \"Normal\", -1: \"Anomaly\"})\n",
    "\n",
    "# Add back \n",
    "df['Anomaly Label'] = \"Normal\"\n",
    "df.loc[anomaly_labels.index, 'Anomaly Label'] = anomaly_labels\n",
    "\n",
    "# result\n",
    "df.to_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Anomaly_Detection/x.csv\", index=False)\n",
    "\n",
    "print(\" Anomaly detection completed. Output saved as 'x.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ae74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sorted!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Anomaly_Detection/x.csv\")\n",
    "\n",
    "# Sort clients in ascending order\n",
    "df_sorted = df.sort_values(by='Anomaly Label', ascending=True)\n",
    "\n",
    "#  Save\n",
    "df_sorted.to_csv(\"/Users/rg/ACADEMICS/Interview/Connected Data Comapany/MAY/Dataset/Anomaly_Detection/clients_sorted_by_anomalies.csv\", index=False)\n",
    "\n",
    "print(\"\\n sorted!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373241a7",
   "metadata": {},
   "source": [
    "- Out of all clients analyzed, 29 clients were flagged as anomalies.\n",
    "\n",
    "- These clients show unusual behavior — like high arrears with high scores, or very low arrears with extremely low scores.\n",
    "\n",
    "- These cases are maybe data quality issues or special clients needs deeper inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b227b50",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
